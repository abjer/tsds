{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Spatial stuff\n",
    "\n",
    "### Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import requests\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# spatial stuff\n",
    "import geopandas as gpd\n",
    "import fiona\n",
    "import folium\n",
    "import shapely"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Extra functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def convert_to_danish_crs(df):\n",
    "    df.to_crs(epsg=25832, inplace=True)\n",
    "\n",
    "\n",
    "from scipy.spatial import Voronoi\n",
    "\n",
    "# The function below is taken from https://gist.github.com/pv/8036995\n",
    "\n",
    "def voronoi_finite_polygons_2d(vor, radius=None):\n",
    "    \"\"\"\n",
    "    Reconstruct infinite voronoi regions in a 2D diagram to finite\n",
    "    regions.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    vor : Voronoi\n",
    "        Input diagram\n",
    "    radius : float, optional\n",
    "        Distance to 'points at infinity'.\n",
    "    Returns\n",
    "    -------\n",
    "    regions : list of tuples\n",
    "        Indices of vertices in each revised Voronoi regions.\n",
    "    vertices : list of tuples\n",
    "        Coordinates for revised Voronoi vertices. Same as coordinates\n",
    "        of input vertices, with 'points at infinity' appended to the\n",
    "        end.\n",
    "        \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    if vor.points.shape[1] != 2:\n",
    "        raise ValueError(\"Requires 2D input\")\n",
    "\n",
    "    new_regions = []\n",
    "    new_vertices = vor.vertices.tolist()\n",
    "\n",
    "    center = vor.points.mean(axis=0)\n",
    "    if radius is None:\n",
    "        radius = vor.points.ptp().max()*2\n",
    "\n",
    "    # Construct a map containing all ridges for a given point\n",
    "    all_ridges = {}\n",
    "    for (p1, p2), (v1, v2) in zip(vor.ridge_points, vor.ridge_vertices):\n",
    "        all_ridges.setdefault(p1, []).append((p2, v1, v2))\n",
    "        all_ridges.setdefault(p2, []).append((p1, v1, v2))\n",
    "\n",
    "    \n",
    "    # Reconstruct infinite regions\n",
    "    for p1, region in enumerate(vor.point_region):\n",
    "        vertices = vor.regions[region]\n",
    "\n",
    "        if all(v >= 0 for v in vertices):\n",
    "            # finite region\n",
    "            new_regions.append(vertices)\n",
    "            continue\n",
    "\n",
    "        # reconstruct a non-finite region\n",
    "        ridges = all_ridges[p1]\n",
    "        new_region = [v for v in vertices if v >= 0]\n",
    "\n",
    "        for p2, v1, v2 in ridges:\n",
    "            if v2 < 0:\n",
    "                v1, v2 = v2, v1\n",
    "            if v1 >= 0:\n",
    "                # finite ridge: already in the region\n",
    "                continue\n",
    "\n",
    "            # Compute the missing endpoint of an infinite ridge\n",
    "\n",
    "            t = vor.points[p2] - vor.points[p1] # tangent\n",
    "            t /= np.linalg.norm(t)\n",
    "            n = np.array([-t[1], t[0]])  # normal\n",
    "\n",
    "            midpoint = vor.points[[p1, p2]].mean(axis=0)\n",
    "            direction = np.sign(np.dot(midpoint - center, n)) * n\n",
    "            far_point = vor.vertices[v2] + direction * radius\n",
    "\n",
    "            new_region.append(len(new_vertices))\n",
    "            new_vertices.append(far_point.tolist())\n",
    "\n",
    "        # sort region counterclockwise\n",
    "        vs = np.asarray([new_vertices[v] for v in new_region])\n",
    "        c = vs.mean(axis=0)\n",
    "        angles = np.arctan2(vs[:,1] - c[1], vs[:,0] - c[0])\n",
    "        new_region = np.array(new_region)[np.argsort(angles)]\n",
    "\n",
    "        # finish\n",
    "        new_regions.append(new_region.tolist())\n",
    "\n",
    "    return new_regions, np.asarray(new_vertices)\n",
    "\n",
    "\n",
    "# Making a wrapper function for geopandas\n",
    "\n",
    "def voronoi_wrapper(points, origin_geom):\n",
    "    '''\n",
    "    Returns a series of Voronoi shapely objects contruced\n",
    "    from the centroids.\n",
    "    '''\n",
    "    \n",
    "    vor = Voronoi(points)\n",
    "    \n",
    "    regions, vertices = voronoi_finite_polygons_2d(vor)\n",
    "    \n",
    "    def _polygon_intersect(points):\n",
    "        poly = shapely.geometry.Polygon(points)\n",
    "        poly_intersect_origin = poly.intersection(origin_geom)\n",
    "        return poly_intersect_origin\n",
    "    \n",
    "    poly_list = [_polygon_intersect(vertices[region]) for region in regions]\n",
    "    \n",
    "    return gpd.GeoSeries(poly_list, index=points.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Administrative areas of Denmark\n",
    "\n",
    "We start off by loading adminstrative shape files for parishes and municipalities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "admin_dk_repo = 'https://raw.githubusercontent.com/ok-dk/dagi/master/geojson/'\n",
    "\n",
    "\n",
    "# parishes (church districts)\n",
    "sogne = gpd.read_file(admin_dk_repo+'sogne.geojson')    \n",
    "\n",
    "# municipalities\n",
    "kommuner = gpd.read_file(admin_dk_repo+'kommuner.geojson')\n",
    "\n",
    "# rename columns and change coordinate system\n",
    "for gdf in sogne, kommuner:\n",
    "    gdf.columns = gdf.columns.str.lower()\n",
    "    gdf.to_crs(epsg=25832, inplace=True)\n",
    "\n",
    "# information for municipality\n",
    "kommune_info = pd.read_json('https://dawa.aws.dk/kommuner')\\\n",
    "                .pipe(lambda df: \\\n",
    "                        df.assign(komkode=df.kode.astype(str).str.zfill(4)))\\\n",
    "                .loc[:,['komkode','regionskode']]\\\n",
    "                \n",
    "\n",
    "region_info = pd.read_json('https://dawa.aws.dk/regioner/')\\\n",
    "                .loc[:,['kode','navn']]\\\n",
    "                .add_prefix('regions')\n",
    "\n",
    "kommuner = kommuner\\\n",
    "                .merge(kommune_info,how='left')\\\n",
    "                .merge(region_info,how='left')\n",
    "\n",
    "# select Copenhagen shapes\n",
    "select_cph = kommuner.komnavn.isin(['København', 'Frederiksberg'])\n",
    "kommuner_cph = kommuner[select_cph]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "From the administrative areas we can make unified shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# DK as one shape\n",
    "denmark_shape = kommuner.unary_union\n",
    "\n",
    "# Capital region (without Bornholm) as one shape\n",
    "cap_reg = kommuner.regionsnavn.isin(['Region Hovedstaden'])\n",
    "non_bornholm = kommuner.bounds.minx<800000\n",
    "\n",
    "kommuner_select = kommuner[cap_reg & non_bornholm]\n",
    "cap_region = kommuner_select.unary_union\n",
    "\n",
    "# Capital region (without Bornholm) as one shape\n",
    "sealand_reg = kommuner.regionsnavn.isin(['Region Hovedstaden', 'Region Sjælland'])\n",
    "non_bornholm = ~ kommuner.komnavn.isin(['Bornholm', 'Christiansø'])\n",
    "\n",
    "kommuner_select_sealand = kommuner[sealand_reg & non_bornholm]\n",
    "sealand_shape = kommuner_select_sealand.unary_union"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots and structured data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### World countries as shapes in geodataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "world_map = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "country_shapes = world_map.geometry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Youth in Copenhagen  \n",
    "Use the example DST api and merge with municipal shapes \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run statistics_denmark_api.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge data with shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_parish_young = sogne.merge(youth_stats[youth_stats.year==2010])\n",
    "        \n",
    "# select capital region \n",
    "gdf_parish_young_cap_reg = gdf_parish_young[gdf_parish_young.intersects(cap_region)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Plot youth count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "vmin, vmax = 0, 7500\n",
    "ax = gdf_parish_young_cap_reg\\\n",
    "    .plot(column=c_count, \n",
    "          figsize=(11,8), \n",
    "          vmin=vmin, \n",
    "          vmax=vmax,\n",
    "          cmap='viridis')\n",
    "\n",
    "# add colorbar\n",
    "f_cph_young_count = ax.get_figure()\n",
    "cax = f_cph_young_count.add_axes([0.9, 0.1, 0.03, 0.8])\n",
    "sm = plt.cm.ScalarMappable(cmap='viridis', norm=plt.Normalize(vmin=vmin, vmax=vmax))\n",
    "# fake up the array of the scalar mappable. Urgh...\n",
    "sm._A = []\n",
    "f_cph_young_count.colorbar(sm, cax=cax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Plot youth share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "vmin, vmax = 0, .5\n",
    "ax = gdf_parish_young_cap_reg\\\n",
    "        .plot(column=c_share, \n",
    "              figsize=(11,8), \n",
    "              vmin=vmin, \n",
    "              vmax=vmax,\n",
    "              cmap='viridis')\n",
    "\n",
    "# add colorbar\n",
    "f_cph_young = ax.get_figure()\n",
    "cax = f_cph_young.add_axes([0.9, 0.1, 0.03, 0.8])\n",
    "sm = plt.cm.ScalarMappable(cmap='viridis', norm=plt.Normalize(vmin=vmin, vmax=vmax))\n",
    "# fake up the array of the scalar mappable. Urgh...\n",
    "sm._A = []\n",
    "f_cph_young.colorbar(sm, cax=cax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Danish house prices from sales data\n",
    "\n",
    "Note this data is made from Snorre's scraping code.\n",
    "\n",
    "<p><FONT color=red>You need to have downloaded the data before starting this script. See the accompanying exercises for instructions.</FONT></p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_gdf = gpd.read_file('house_prices.geojson')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Select 2012 price sales data and make Voronoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# some address coordinates have multiple sales\n",
    "# we handle this by making a slight perturbation\n",
    "price_gdf['n'] = price_gdf.geometry.y\n",
    "price_gdf['e'] = price_gdf.geometry.x\n",
    "\n",
    "price_gdf[['e', 'n']] += np.random.normal(scale=100, size=(len(price_gdf), 2))\n",
    "\n",
    "# select 2012 sales and remove outliers\n",
    "selection = (price_gdf.sale_year==2012) & \\\n",
    "            (price_gdf.price_area.between(1000,100000))\n",
    "\n",
    "# make selection, reset_index and copy\n",
    "prices_12 = price_gdf[selection].reset_index(drop=True).copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Voronoi prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# make voronoi shapes\n",
    "voronoi_geom = voronoi_wrapper(prices_12[['e', 'n']].copy(), \n",
    "                               sealand_shape)\n",
    "\n",
    "# turn into new GeoDataFrame for plotting\n",
    "prices_12_vor = gpd.GeoDataFrame(data=prices_12.copy().drop('geometry',axis=1),\n",
    "                                 geometry=voronoi_geom)\n",
    "\n",
    "# make plots\n",
    "f_price_pointcloud,ax = plt.subplots(figsize=(10,8))\n",
    "prices_12.plot(column='price_area_log', markersize=4, ax=ax)\n",
    "\n",
    "f_price_voronoi,ax = plt.subplots(figsize=(10,8))\n",
    "prices_12_vor.plot(column='price_area_log', ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open Street Maps (OSM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Point\n",
    "\n",
    "\n",
    "overpass_base = \"http://overpass-api.de/api/interpreter\"\n",
    "\n",
    "def query_overpass_gdf(tag, subtag='*', place='DK'):\n",
    "    q = f\"\"\"\n",
    "         [out:json];\n",
    "         area[\"ISO3166-1\"=\"{place}\"][admin_level=2];\n",
    "         (node[\"{tag}\"=\"{subtag}\"](area);\n",
    "          way[\"{tag}\"=\"{subtag}\"](area);\n",
    "          rel[\"{tag}\"=\"{subtag}\"](area);\n",
    "         );\n",
    "         out center;\n",
    "         \"\"\"\n",
    "    \n",
    "    response = requests.get(overpass_base, params={'data': q})    \n",
    "    df = pd.DataFrame(response.json()['elements'])\n",
    "    \n",
    "    points = df[['lon','lat']].apply(Point, 1)\n",
    "    gdf = gpd.GeoDataFrame(df,\n",
    "                           geometry = points,\n",
    "                           crs = {'init': 'epsg:4326'})\n",
    "\n",
    "    gdf.to_crs(epsg=25832, inplace=True)\n",
    "    \n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restaurant plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_restaurant = query_overpass_gdf('amenity', 'restaurant')\n",
    "f_restaurant_buffer, ax = plt.subplots(figsize=(14,8))\n",
    "gs_rest_1km = gdf_restaurant.buffer(2500)\n",
    "gs_rest_1km.plot(alpha=.3, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supermarket plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_supermarket = query_overpass_gdf('shop', 'supermarket')\n",
    "gdf_supermarket['name'] = gdf_supermarket.tags.str['name'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from folium.plugins import MarkerCluster\n",
    "\n",
    "m_dk_supermarket_cph = folium.Map(location=[55.7, 12.5],\n",
    "                              tiles='Stamen Toner',\n",
    "                              zoom_start=10)\n",
    "\n",
    "marker_cluster_cph = MarkerCluster(\n",
    "    overlay=True,\n",
    "    control=False,\n",
    "    icon_create_function=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from folium.plugins import MarkerCluster\n",
    "\n",
    "m_dk_supermarket = folium.Map(location=[55.7, 12.5],\n",
    "                              tiles='Stamen Toner',\n",
    "                              zoom_start=10)\n",
    "\n",
    "marker_cluster = MarkerCluster(\n",
    "    overlay=True,\n",
    "    control=False,\n",
    "    icon_create_function=None)\n",
    "\n",
    "geoms = gdf_supermarket.set_index('name')[['lat','lon']].iterrows()\n",
    "for name, point in geoms:        \n",
    "    marker = folium.Marker(location=[point.lat, point.lon])\n",
    "    n = name.replace('ø','oe').replace('å','aa').replace('æ','ae').replace(\"'\",'')\n",
    "    \n",
    "    popup = n\n",
    "    folium.Popup(popup).add_to(marker)\n",
    "    marker_cluster.add_child(marker)\n",
    "    \n",
    "marker_cluster.add_to(m_dk_supermarket)\n",
    "\n",
    "m_dk_supermarket  "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

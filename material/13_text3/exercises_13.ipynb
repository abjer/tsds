{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Before you run solve this make sure you have created a new conda environment.\n",
    "run the following commands in your commandline\n",
    "<pre><code>\n",
    "conda create -n deepmoji anaconda\n",
    "source activate deepmoji\n",
    "## add to jupyter notebook list\n",
    "python -m ipykernel install --user --name deepmoji --display-name \"Python (deepmoji)\"</code></pre>\n",
    "\n",
    "### Or preferably load this notebook into [google colab](https://colab.research.google.com)   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer learning and bias detection\n",
    "Today we are gonna practice adopting pretrained language models to power our classifiers. \n",
    "Using a pretrained model as input, both means a potentially huge gain in performance, but also a potentially problematic introduction of bias. \n",
    "\n",
    "Since you are not controlling the population / dataset from which your model learns it is hard to guarantee that the models do not come with certain biases builtin. \n",
    "\n",
    "As the pretrained models come \"free\", you should instead spent ressources on investigating and potentially eliminating biases (bias correction). Today you will practice investigating the biases. \n",
    "\n",
    "We will do this using two datasets: \n",
    "1. From the paper:  \"Examining Gender and Race Bias in Two Hundred Sentiment Analysis Systems\" by Kiritchenko & Mohammad 2018:. [data](https://saifmohammad.com/WebDocs/EEC/Equity-Evaluation-Corpus.zip)\n",
    "\n",
    "2. Kaggle Toxicity Classification: https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification/data\n",
    "Follow the url. Sign in and download the zip file.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Download the equity evaluation corpus\n",
    "import requests\n",
    "response = requests.get('https://saifmohammad.com/WebDocs/EEC/Equity-Evaluation-Corpus.zip')\n",
    "\n",
    "with open('Equity-Evaluation-Corpus.zip','wb') as f:\n",
    "    f.write(response.content)\n",
    "\n",
    "import zipfile\n",
    "zip_ref = zipfile.ZipFile('Equity-Evaluation-Corpus.zip', 'r')\n",
    "directory_to_extract_to = 'bias_dataset'\n",
    "\n",
    "import os\n",
    "if not os.path.isdir(directory_to_extract_to):\n",
    "    os.mkdir(directory_to_extract_to)\n",
    "zip_ref.extractall(directory_to_extract_to)\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "directory_to_extract_to = 'bias_dataset'\n",
    "bias_df = pd.read_csv(directory_to_extract_to+'/Equity-Evaluation-Corpus.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Template</th>\n",
       "      <th>Person</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Race</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Emotion word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-En-mystery-05498</td>\n",
       "      <td>Alonzo feels angry.</td>\n",
       "      <td>&lt;person subject&gt; feels &lt;emotion word&gt;.</td>\n",
       "      <td>Alonzo</td>\n",
       "      <td>male</td>\n",
       "      <td>African-American</td>\n",
       "      <td>anger</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-En-mystery-11722</td>\n",
       "      <td>Alonzo feels furious.</td>\n",
       "      <td>&lt;person subject&gt; feels &lt;emotion word&gt;.</td>\n",
       "      <td>Alonzo</td>\n",
       "      <td>male</td>\n",
       "      <td>African-American</td>\n",
       "      <td>anger</td>\n",
       "      <td>furious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-En-mystery-11364</td>\n",
       "      <td>Alonzo feels irritated.</td>\n",
       "      <td>&lt;person subject&gt; feels &lt;emotion word&gt;.</td>\n",
       "      <td>Alonzo</td>\n",
       "      <td>male</td>\n",
       "      <td>African-American</td>\n",
       "      <td>anger</td>\n",
       "      <td>irritated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-En-mystery-14320</td>\n",
       "      <td>Alonzo feels enraged.</td>\n",
       "      <td>&lt;person subject&gt; feels &lt;emotion word&gt;.</td>\n",
       "      <td>Alonzo</td>\n",
       "      <td>male</td>\n",
       "      <td>African-American</td>\n",
       "      <td>anger</td>\n",
       "      <td>enraged</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-En-mystery-14114</td>\n",
       "      <td>Alonzo feels annoyed.</td>\n",
       "      <td>&lt;person subject&gt; feels &lt;emotion word&gt;.</td>\n",
       "      <td>Alonzo</td>\n",
       "      <td>male</td>\n",
       "      <td>African-American</td>\n",
       "      <td>anger</td>\n",
       "      <td>annoyed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      ID                 Sentence  \\\n",
       "0  2018-En-mystery-05498      Alonzo feels angry.   \n",
       "1  2018-En-mystery-11722    Alonzo feels furious.   \n",
       "2  2018-En-mystery-11364  Alonzo feels irritated.   \n",
       "3  2018-En-mystery-14320    Alonzo feels enraged.   \n",
       "4  2018-En-mystery-14114    Alonzo feels annoyed.   \n",
       "\n",
       "                                 Template  Person Gender              Race  \\\n",
       "0  <person subject> feels <emotion word>.  Alonzo   male  African-American   \n",
       "1  <person subject> feels <emotion word>.  Alonzo   male  African-American   \n",
       "2  <person subject> feels <emotion word>.  Alonzo   male  African-American   \n",
       "3  <person subject> feels <emotion word>.  Alonzo   male  African-American   \n",
       "4  <person subject> feels <emotion word>.  Alonzo   male  African-American   \n",
       "\n",
       "  Emotion Emotion word  \n",
       "0   anger        angry  \n",
       "1   anger      furious  \n",
       "2   anger    irritated  \n",
       "3   anger      enraged  \n",
       "4   anger      annoyed  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "bias_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains short sentences expressing a simple sentiment, but with changing characters connotating different genders and ethnicities. This allows you to test your classifier in relation to these biases.\n",
    "\n",
    "Today we will test two types of classifiers.\n",
    "\n",
    "- Baseline classifier trained yourself on a given dataset:\n",
    "    - pick either fasttext.\n",
    "    - or the NBLOG (Naive Bayes features feed into a Logistic Regression)\n",
    "    \n",
    "- And the Deepmoji classifier.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the DeepMoji encoder\n",
    "First we shall see what biases the [DeepMoji](https://arxiv.org/pdf/1708.00524.pdf) encoder has out of the box.\n",
    "\n",
    "In this way we get to practice loading and interacting with a pretrained model.\n",
    "\n",
    "DeepMoji was originally conceived using [Keras](https://github.com/bfelbo/DeepMoji), but since you are use to PyTorch we shall use the [TorchMoji](https://github.com/huggingface/torchMoji) implementation.\n",
    "\n",
    "Loading it is straightforward using git."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## clone the repository\n",
    "! git clone https://github.com/huggingface/torchMoji.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## download the pretrained model's weights using their script\n",
    "! python scripts/download_weights.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# navigate to the torchmoji folder\n",
    "import os\n",
    "os.chdir('TorchMoji')\n",
    "## install dependencies\n",
    "! pip install -e .\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If already downloaded elsewhere add the deepmoji directory to the sys.path so python can import it automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add to sys.path\n",
    "import sys\n",
    "base_path = '' # change if you have downloaded folder elsewhere.\n",
    "#base_path = '/mnt/b0c8e396-e5ba-4614-be6f-146c4c861ab3/torchMoji/' ## path to the torchmoji directory\n",
    "#sys.path.insert(0, base_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load model and tokenizer\n",
    "from torchmoji.sentence_tokenizer import SentenceTokenizer\n",
    "# load the deepmoji encoder that transforms text to emojies.\n",
    "from torchmoji.model_def import torchmoji_emojis\n",
    "from torchmoji.global_variables import PRETRAINED_PATH, VOCAB_PATH\n",
    "import json,csv, numpy as np\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "\n",
    "\n",
    "## set the max context length\n",
    "max_token = 30 ## This will not work for longer texts,\n",
    "################# here you should consider splitting each text into smaller segments.\n",
    "\n",
    "# Load vocab (i.e. the index of each word in the vector representation)\n",
    "with open(VOCAB_PATH, 'r') as f:\n",
    "    vocabulary = json.load(f)\n",
    "\n",
    "# initialize tokenizer\n",
    "sentence_tokenizer = SentenceTokenizer(vocabulary, max_token)\n",
    "# load model\n",
    "model = torchmoji_emojis(PRETRAINED_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model outputs a vector of length 64 representing the probability of 64 emojiies.\n",
    "\n",
    "We can find the index of the emojies with descriptions in the data folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0', ':joy:'),\n",
       " ('1', ':unamused:'),\n",
       " ('2', ':weary:'),\n",
       " ('3', ':sob:'),\n",
       " ('4', ':heart_eyes:'),\n",
       " ('5', ':pensive:'),\n",
       " ('6', ':ok_hand:'),\n",
       " ('7', ':blush:'),\n",
       " ('8', ':heart:'),\n",
       " ('9', ':smirk:')]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(base_path+'data/emoji_codes.json') as f:\n",
    "    emoji_desc = json.load(f)\n",
    "list(emoji_desc.items())[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know use this index and the emoji package to translate the index to emojiies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ðŸ˜‚', ':joy:')"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import emoji\n",
    "def translate_emoji(emoji_descr):\n",
    "    if emoji_descr in emoji.unicode_codes.EMOJI_ALIAS_UNICODE:\n",
    "        return emoji.unicode_codes.EMOJI_ALIAS_UNICODE[emoji_descr]\n",
    "    if emoji_descr in emoji.unicode_codes.EMOJI_UNICODE:\n",
    "        return emoji.unicode_codes.EMOJI_UNICODE[emoji_descr]\n",
    "    return emoji_descr\n",
    "to_emoji = [translate_emoji(desc) for i,desc in sorted(emoji_desc.items(),key=lambda x: int(x[0]))]\n",
    "to_emoji_desc = [desc for i,desc in sorted(emoji_desc.items(),key=lambda x: int(x[0]))]\n",
    "\n",
    "## index \n",
    "to_emoji[0],to_emoji_desc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to encode the text as emojis\n",
    "\n",
    "**note we are not using it for transfer learning** but simple as a pretrained classifier.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 13.1.1\n",
    "Use the sentence_tokenizer defined above to tokenize the documents.\n",
    "\n",
    "see example in the torchmoji examples [e.g.](https://github.com/huggingface/torchMoji/blob/master/examples/encode_texts.py) folder for help.\n",
    "\n",
    "Inspect the tokenized documents to see the format. Try to convert them back using <code>vocabulary</code> variable defined earlier.\n",
    "\n",
    "**- Hint this means reversing the vocabulary dictionary.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Answer to ex. 13.1.1. here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 13.1.2\n",
    "Encode the tokenized sentences and wrap it in a function.\n",
    "- Hint: Do a forward pass of the model on the tokenized data.\n",
    "    - check [here](https://github.com/huggingface/torchMoji/blob/master/examples/encode_texts.py) for help \n",
    "\n",
    "For larger datasets and with longer sentences encoding is problematic if not done in batches. \n",
    "\n",
    "Write a for loop that takes only 256 tokenized documents at a time and concatenate them to a dataframe in the end.\n",
    "\n",
    "Use the <code>to_emoji</code> list as columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Answer to ex 13.1.2 here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex. 13.1.3\n",
    "- Join the output of Deepmoji with the bias dataframe columns (Race, Gender and Emotion)\n",
    "    - Make sure Race count and Gender counts are equal after join.\n",
    "\n",
    "Investigate if there are significant differences in relation to **Race** (Race column).\n",
    "\n",
    "- See which types of emojies are most different.\n",
    "\n",
    "\n",
    "- Make a dictionary mapping emojiis to different classes, either happy, sad, angry etc.\n",
    "- HINT: Fastests way is to loop through the list of emojiies <code>to_emoji</code> and use the <code>input()</code> to input the class.\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Answer to ex. 13.1.3 here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex.13.1.4 - See which emotions are most biased\n",
    "\n",
    "- Groupby Emotion and Race and calculate absolute difference in emoji encoding. \n",
    "    - hint: first groupby emotion and race, calculate mean, then diff, then abs and then sum.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Answer to ex. 13.1.4 here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hostility and Minority Dataset (Kaggle Toxicity Classification)\n",
    "**Context**\n",
    "All outcome and minority variables are crowdsourced annotations and variables are expressed and percentage of annotators marking the category. This means that to create categorical outcomes we should apply a cutoff. The dataset provider suggests 0.5. \n",
    "\n",
    "**Ex.13.2.1:** \n",
    "- Define a variable <code>minority_cols</code> as a list of column names of the minorities.\n",
    "- Define a variable <code>outcome_cols</code> as a list of column names of the minorities.\n",
    "- Create a categorical version of each variable in the outcome cols and minority cols.\n",
    "\n",
    "\n",
    "**Ex. 13.2.2:** The dataset is fairly large so subsampling will be a good idea (e.g. 25000 samples) where minorities are upsampled. Do a subsample of 1000 for each minority including a none category. \n",
    "\n",
    "**Ex 13.2.3:** Train one of the baseline classifiers (see lecture 13 for bow based and fasttext) on the hostility and minority dataset.\n",
    "\n",
    "**Ex.13.2.4:** Investigate biases in relation to minority groups.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Answers to ex 13.2.x here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus \n",
    "So far we have not done any real transfer learning. For this exercise you should visit some of the major models and investigate how to adopt the model to your own dataset.\n",
    "\n",
    "BERT - [COLAB Example](https://colab.research.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb)\n",
    "\n",
    "DeepMoji:\n",
    "Try the deepmoji finetuning example [here](https://colab.research.google.com/drive/1IsV5a_tr2c5OVdKnX_PyGjoRWW8DUG0S)\n",
    "    - HINT: Inspect the load_benchmark data to see how to make your own dataset conform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Answer to bonus question here]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
